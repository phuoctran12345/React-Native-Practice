import React, { useEffect, useRef, useState } from 'react';
import { View, StyleSheet, Text, ActivityIndicator, Alert, Dimensions, Platform, PanResponder } from 'react-native';
import { Camera, CameraView } from 'expo-camera';
import { GLView } from 'expo-gl';
import { Renderer, loadAsync } from 'expo-three';
import * as THREE from 'three';
import { Asset } from 'expo-asset';
// ‚úÖ ORBITCONTROLS KH√îNG T∆Ø∆†NG TH√çCH V·ªöI REACT NATIVE
import { GestureHandlerRootView, PanGestureHandler, State } from 'react-native-gesture-handler';
import { getGLBModelFromQRData, getGLBModelConfig } from '../utils/modelData';

interface PokemonARViewerProps {
  onClose: () => void;
}

const PokemonARViewer: React.FC<PokemonARViewerProps> = ({ onClose }) => {
  const [hasPermission, setHasPermission] = useState<boolean | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [loadingProgress, setLoadingProgress] = useState(0);
  const [modelInfo, setModelInfo] = useState<string>('');
  const [showDebugControls, setShowDebugControls] = useState(false);
  const [debugInfo, setDebugInfo] = useState<any>({});
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);
  const modelRef = useRef<THREE.Object3D | null>(null);
  const rotationRef = useRef({ x: 0, y: 0 });
  const sceneRef = useRef<THREE.Scene | null>(null);
  const cameraRef = useRef<THREE.Camera | null>(null);
  const rendererRef = useRef<THREE.WebGLRenderer | null>(null);
  const mixerRef = useRef<THREE.AnimationMixer | null>(null);
  const clockRef = useRef(new THREE.Clock());
  // ‚úÖ ORBITCONTROLS KH√îNG T∆Ø∆†NG TH√çCH V·ªöI REACT NATIVE
  const [scannedData, setScannedData] = useState<string | null>(null);
  const [currentAnimation, setCurrentAnimation] = useState<string>('idle');
  const [animationFeedback, setAnimationFeedback] = useState<string>('');
  const [showGestureHint, setShowGestureHint] = useState<boolean>(true);

  // ‚úÖ PANRESPONDER CHO XOAY 360 ƒê·ªò V√Ä ZOOM - CHUY√äN NGHI·ªÜP!
  const [previousRotationX, setPreviousRotationX] = useState(0);
  const [previousRotationY, setPreviousRotationY] = useState(0);
  const [previousScale, setPreviousScale] = useState(1);
  const [isRotating, setIsRotating] = useState(false);
  const [isZooming, setIsZooming] = useState(false);

  // ‚úÖ PANRESPONDER CHO 3D INTERACTION - X·ª¨ L√ù C·ª¨ CH·ªà LI√äN T·ª§C!

  // ‚úÖ PANRESPONDER CHO 3D INTERACTION - CHUY√äN NGHI·ªÜP!
  const panResponder = PanResponder.create({
    onStartShouldSetPanResponder: () => {
      return true;
    },
    onMoveShouldSetPanResponder: () => {
      return true;
    },
    
    onPanResponderGrant: (evt) => {
      // ‚úÖ ·∫®N GESTURE HINT SAU KHI USER T∆Ø∆†NG T√ÅC
      if (showGestureHint) {
        setShowGestureHint(false);
      }
      
      // ‚úÖ SETUP INITIAL STATE
      setIsRotating(true);
      setIsZooming(false);
    },
    
    onPanResponderMove: (evt, gestureState) => {
      if (!modelRef.current) {
        return;
      }
      
      const touches = evt.nativeEvent.touches;
      
      if (touches.length === 1) {
        // ‚úÖ THU·∫¨T TO√ÅN XOAY 360 ƒê·ªò - SINGLE TOUCH
        const ROTATION_SENSITIVITY = 0.01;
        const deltaX = gestureState.dx * ROTATION_SENSITIVITY;
        const deltaY = gestureState.dy * ROTATION_SENSITIVITY;
        
        const currentRotationY = previousRotationY + deltaX;
        const currentRotationX = previousRotationX + deltaY;
        
        // ‚úÖ GI·ªöI H·∫†N G√ìC XOAY D·ªåC
        const clampedRotationX = Math.max(-Math.PI/2, Math.min(Math.PI/2, currentRotationX));
        
        // ‚úÖ C·∫¨P NH·∫¨T MODEL
        modelRef.current.rotation.y = currentRotationY;
        modelRef.current.rotation.x = clampedRotationX;
        
      } else if (touches.length === 2) {
        // ‚úÖ THU·∫¨T TO√ÅN ZOOM IN/OUT - MULTI TOUCH
        const currentDistance = Math.sqrt(
          Math.pow(touches[0].pageX - touches[1].pageX, 2) + 
          Math.pow(touches[0].pageY - touches[1].pageY, 2)
        );
        
        // T√≠nh scale d·ª±a tr√™n distance (simplified)
        const scale = Math.max(0.5, Math.min(3.0, currentDistance / 200));
        const originalScale = (modelRef.current as any).originalScale || 0.0129265882742369;
        const targetScale = originalScale * scale;
        
        // ‚úÖ C·∫¨P NH·∫¨T MODEL
        modelRef.current.scale.setScalar(targetScale);
      }
    },
    
    onPanResponderRelease: (evt) => {
      // ‚úÖ L∆ØU TR·∫†NG TH√ÅI TR∆Ø·ªöC ƒê√ì KHI GESTURE K·∫æT TH√öC
        if (modelRef.current) {
        setPreviousRotationX(modelRef.current.rotation.x);
        setPreviousRotationY(modelRef.current.rotation.y);
        setPreviousScale(modelRef.current.scale.x);
      }
      
      setIsRotating(false);
      setIsZooming(false);
    }
  });

  // ‚úÖ TC6.2: SCREEN COMPATIBILITY
  const screenData = Dimensions.get('window');
  const isIOS = Platform.OS === 'ios';
  const hasNotch = screenData.height > 800; // Approximate notch detection

  // ‚úÖ HELPER FUNCTION ƒê·ªÇ T√çNH KHO·∫¢NG C√ÅCH GI·ªÆA 2 TOUCH
  const getDistance = (touch1: any, touch2: any) => {
    const dx = touch1.pageX - touch2.pageX;
    const dy = touch1.pageY - touch2.pageY;
    return Math.sqrt(dx * dx + dy * dy);
  };

  // ‚úÖ FORCE LOAD FOX.PNG TEXTURE - GI·∫¢I PH√ÅP CU·ªêI C√ôNG
  const forceLoadFoxTexture = async (model: THREE.Object3D) => {
    console.log('ü¶ä === LOAD FOX.PNG TEXTURE ===');
    
    try {
      // ‚úÖ B∆Ø·ªöC 1: DOWNLOAD FOX.PNG ASSET TR∆Ø·ªöC
      console.log('ü¶ä Downloading Fox.png asset...');
      const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
      await foxAsset.downloadAsync();
      console.log('‚úÖ Fox.png downloaded, URI:', foxAsset.uri);
      
      // ‚úÖ B∆Ø·ªöC 2: LOAD TEXTURE FROM DOWNLOADED ASSET
      const textureLoader = new THREE.TextureLoader();
      
      const foxTexturePromise = new Promise<THREE.Texture>((resolve, reject) => {
        console.log('ü¶ä Loading texture from URI:', foxAsset.uri);
        
        textureLoader.load(
          foxAsset.uri,
          (texture) => {
            console.log('‚úÖ Fox.png texture loaded successfully!');
            
            // ‚úÖ SETUP TEXTURE PROPERTIES
            texture.needsUpdate = true;
            texture.wrapS = THREE.ClampToEdgeWrapping;
            texture.wrapT = THREE.ClampToEdgeWrapping;
            texture.flipY = false;
            // @ts-ignore
            texture.encoding = THREE.sRGBEncoding;
            
            resolve(texture);
          },
          undefined,
          (error) => {
            console.error('‚ùå Failed to load Fox.png:', error);
            reject(error);
          }
        );
      });
      
      const foxTexture = await foxTexturePromise;
      
      // ‚úÖ B∆Ø·ªöC 2: √ÅP D·ª§NG TEXTURE CHO T·∫§T C·∫¢ MESH
      model.traverse((child: any) => {
        if (child.isMesh && child.material) {
          console.log(`ü¶ä Applying Fox.png texture to mesh: ${child.name}`);
          
          // ‚úÖ CLEAR MATERIAL COLOR
          child.material.color.setHex(0xffffff);
          
          // ‚úÖ CLEAR EMISSIVE
          child.material.emissive.setHex(0x000000);
          child.material.emissiveIntensity = 0;
          
          // ‚úÖ DISABLE VERTEX COLORS
          child.material.vertexColors = false;
          
          // ‚úÖ APPLY TEXTURE
          child.material.map = foxTexture.clone();
          child.material.map.needsUpdate = true;
          
          // ‚úÖ FORCE UPDATE MATERIAL
          child.material.needsUpdate = true;
          
          console.log('‚úÖ Texture applied to:', child.name);
        }
      });
      
      // ‚úÖ B∆Ø·ªöC 3: TH√äM √ÅNH S√ÅNG M·∫†NH H∆†N
      if (sceneRef.current) {
        // Clear existing lights
        const lights = sceneRef.current.children.filter(child => child.type.includes('Light'));
        lights.forEach(light => sceneRef.current?.remove(light));
        
        // Add bright ambient light
        const ambientLight = new THREE.AmbientLight(0xffffff, 1.0);
        sceneRef.current.add(ambientLight);
        
        // Add multiple directional lights
        const light1 = new THREE.DirectionalLight(0xffffff, 1.0);
        light1.position.set(5, 5, 5);
        sceneRef.current.add(light1);
        
        const light2 = new THREE.DirectionalLight(0xffffff, 0.8);
        light2.position.set(-5, 5, -5);
        sceneRef.current.add(light2);
        
        const light3 = new THREE.DirectionalLight(0xffffff, 0.6);
        light3.position.set(0, 5, 5);
        sceneRef.current.add(light3);
        
        console.log('‚úÖ Bright lighting added to scene');
      }
      
      // ‚úÖ B∆Ø·ªöC 4: FORCE RENDER UPDATE
      if (rendererRef.current && sceneRef.current && cameraRef.current) {
        rendererRef.current.render(sceneRef.current, cameraRef.current);
        console.log('‚úÖ Force render update completed');
      }
      
      console.log('ü¶ä === FOX.PNG TEXTURE LOAD COMPLETE ===');
      
    } catch (error) {
      console.error('‚ùå === FOX.PNG TEXTURE LOAD FAILED ===', error);
    }
  };

  // ‚úÖ CREATE TEXTURE FROM PRELOADED ASSET
  const createTextureFromAsset = async (asset: any) => {
    try {
      const textureLoader = new THREE.TextureLoader();
      
      const texture = textureLoader.load(
        asset.uri,
        (loadedTexture) => {
          return loadedTexture;
        },
        undefined,
        (error) => {
          console.error('‚ùå Failed to create texture:', error);
        }
      );
      
      return texture;
      } catch (error) {
      console.error('‚ùå Error creating texture:', error);
      return null;
    }
  };

  // ‚úÖ FORCE APPLY TEXTURE IMMEDIATELY
  const forceApplyTexture = (model: THREE.Object3D) => {
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        try {
          const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
          const textureLoader = new THREE.TextureLoader();
          
          foxAsset.downloadAsync().then(() => {
            const texture = textureLoader.load(
              foxAsset.uri,
              (loadedTexture) => {
                // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
                child.material.color.setHex(0xffffff);
                child.material.emissive.setHex(0x000000);
                child.material.emissiveIntensity = 0;
                child.material.vertexColors = false;
                
                // ‚úÖ FORCE APPLY TEXTURE
                child.material.map = loadedTexture;
                child.material.map.needsUpdate = true;
                child.material.needsUpdate = true;
                
                // ‚úÖ FORCE RENDER UPDATE FOR iOS
                if (rendererRef.current && sceneRef.current && cameraRef.current) {
                  rendererRef.current.render(sceneRef.current, cameraRef.current);
                }
                
                console.log('ü¶ä Texture applied!');
              },
              undefined,
              (error) => {
                console.error('‚ùå Texture load failed:', error);
              }
            );
          }).catch((error) => {
            console.error('‚ùå Asset download failed:', error);
          });
    } catch (error) {
          console.error('‚ùå Texture creation error:', error);
        }
      }
    });
  };

  // ‚úÖ ALTERNATIVE TEXTURE LOADING APPROACH
  const forceApplyTextureAlternative = (model: THREE.Object3D) => {
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        try {
          // ‚úÖ USE DIRECT URI APPROACH
          const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
      const textureLoader = new THREE.TextureLoader();
          
          // ‚úÖ CREATE TEXTURE DIRECTLY
          const texture = textureLoader.load(
            foxAsset.uri,
            (loadedTexture) => {
              // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
              child.material.color.setHex(0xffffff);
              child.material.emissive.setHex(0x000000);
              child.material.emissiveIntensity = 0;
              child.material.vertexColors = false;
              
              // ‚úÖ FORCE APPLY TEXTURE
              child.material.map = loadedTexture;
              child.material.map.needsUpdate = true;
              child.material.needsUpdate = true;
              
              // ‚úÖ FORCE RENDER UPDATE FOR iOS
              if (rendererRef.current && sceneRef.current && cameraRef.current) {
                rendererRef.current.render(sceneRef.current, cameraRef.current);
                console.log('ü¶ä iOS: Force render update applied!');
              }
              
              // ‚úÖ DISABLE FALLBACK COLOR - FORCE TEXTURE USAGE
              child.material.color.setHex(0xffffff); // Set to white to avoid color interference
              child.material.emissive.setHex(0x000000); // No emissive color
              child.material.emissiveIntensity = 0; // No emissive intensity
              
              // ‚úÖ ENSURE PROPER UV MAPPING SETTINGS
              child.material.map.wrapS = THREE.RepeatWrapping;
              child.material.map.wrapT = THREE.RepeatWrapping;
              child.material.map.flipY = false;
              
              console.log('ü¶ä Alternative texture applied!');
          },
          undefined,
          (error) => {
              console.error('‚ùå Alternative texture failed:', error);
            }
          );
          
          // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
          child.material.color.setHex(0xffffff);
          child.material.emissive.setHex(0x000000);
          child.material.emissiveIntensity = 0;
          child.material.vertexColors = false;
          
          // ‚úÖ FORCE APPLY TEXTURE IMMEDIATELY
          child.material.map = texture;
          child.material.map.needsUpdate = true;
          child.material.needsUpdate = true;
          
        } catch (error) {
          console.error('‚ùå Alternative texture error:', error);
        }
      }
    });
  };

  // ‚úÖ DIRECT IMAGE LOADING APPROACH
  const forceApplyTextureDirectImage = (model: THREE.Object3D) => {
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        
        try {
          // ‚úÖ LOAD IMAGE DIRECTLY
          const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
          
          foxAsset.downloadAsync().then(() => {
            // ‚úÖ CREATE IMAGE ELEMENT
            const img = new Image();
            img.crossOrigin = 'anonymous';
            
            img.onload = () => {
              
              // ‚úÖ CREATE TEXTURE FROM IMAGE WITH PROPER SETTINGS
              const texture = new THREE.Texture(img);
              texture.needsUpdate = true;
      texture.wrapS = THREE.RepeatWrapping;
      texture.wrapT = THREE.RepeatWrapping;
      texture.flipY = false;
              
              // ‚úÖ ENSURE PROPER ENCODING
              // @ts-ignore - encoding property for older Three.js versions
              texture.encoding = THREE.sRGBEncoding;
              texture.format = THREE.RGBAFormat;
              texture.type = THREE.UnsignedByteType;
              
              // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
              child.material.color.setHex(0xffffff);
              child.material.emissive.setHex(0x000000);
              child.material.emissiveIntensity = 0;
              child.material.vertexColors = false;
              
              // ‚úÖ APPLY TEXTURE TO MATERIAL
              child.material.map = texture;
              child.material.map.needsUpdate = true;
              child.material.needsUpdate = true;
              
              // ‚úÖ FORCE RENDER UPDATE FOR iOS
              if (rendererRef.current && sceneRef.current && cameraRef.current) {
                rendererRef.current.render(sceneRef.current, cameraRef.current);
                console.log('ü¶ä iOS: Force render update applied!');
              }
              
              // ‚úÖ DISABLE FALLBACK COLOR - FORCE TEXTURE USAGE
              child.material.color.setHex(0xffffff); // Set to white to avoid color interference
              child.material.emissive.setHex(0x000000); // No emissive color
              child.material.emissiveIntensity = 0; // No emissive intensity
              
              // ‚úÖ FORCE MATERIAL UPDATE
              child.material.needsUpdate = true;
              
              console.log('ü¶ä Direct texture applied!');
              
              // ‚úÖ FORCE RENDER UPDATE
              if (rendererRef.current && sceneRef.current && cameraRef.current) {
                rendererRef.current.render(sceneRef.current, cameraRef.current);
              }
            };
            
            img.onerror = (error) => {
              console.error('‚ùå Direct: Failed to load image:', error);
            };
            
            img.src = foxAsset.uri;
          }).catch((error) => {
            console.error('‚ùå Direct: Failed to download Fox.png asset:', error);
          });
      
    } catch (error) {
          console.error('‚ùå Direct: Error loading image:', error);
        }
      }
    });
  };

  // ‚úÖ TEXTURE LOADER APPROACH
  const forceApplyTextureLoader = (model: THREE.Object3D) => {
    console.log('ü¶ä TextureLoader approach...');
    
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        console.log(`ü¶ä TextureLoader approach for mesh: ${child.name}`);
        
        try {
          // ‚úÖ USE TEXTURE LOADER
          const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
      const textureLoader = new THREE.TextureLoader();
          
          foxAsset.downloadAsync().then(() => {
            console.log('ü¶ä TextureLoader: Fox.png asset downloaded, loading texture...');
            
            // ‚úÖ LOAD TEXTURE WITH PROPER SETTINGS
            const texture = textureLoader.load(
              foxAsset.uri,
              (loadedTexture) => {
                console.log('ü¶ä TextureLoader: Texture loaded successfully!');
                console.log('ü¶ä TextureLoader: Texture details:', {
                  image: loadedTexture.image,
                  width: loadedTexture.image?.width,
                  height: loadedTexture.image?.height,
                  format: loadedTexture.format,
                  type: loadedTexture.type
                });
                
                // ‚úÖ APPLY TEXTURE TO MATERIAL
                child.material.map = loadedTexture;
                child.material.map.needsUpdate = true;
                child.material.needsUpdate = true;
                
                // ‚úÖ ENSURE PROPER SETTINGS
                child.material.map.wrapS = THREE.RepeatWrapping;
                child.material.map.wrapT = THREE.RepeatWrapping;
                child.material.map.flipY = false;
                // @ts-ignore - encoding property for older Three.js versions
                child.material.map.encoding = THREE.sRGBEncoding;
                
                console.log('ü¶ä TextureLoader: Texture applied successfully!');
                console.log('ü¶ä TextureLoader: Material status:', {
                  hasMap: !!child.material.map,
                  mapNeedsUpdate: child.material.map?.needsUpdate,
                  materialNeedsUpdate: child.material.needsUpdate
                });
                
                // ‚úÖ FORCE RENDER UPDATE
                if (rendererRef.current && sceneRef.current && cameraRef.current) {
                  rendererRef.current.render(sceneRef.current, cameraRef.current);
                  console.log('ü¶ä TextureLoader: Force render update applied!');
                }
          },
          undefined,
          (error) => {
                console.error('‚ùå TextureLoader: Failed to load texture:', error);
              }
            );
            
          }).catch((error) => {
            console.error('‚ùå TextureLoader: Failed to download Fox.png asset:', error);
          });
          
        } catch (error) {
          console.error('‚ùå TextureLoader: Error loading texture:', error);
        }
      }
    });
  };

  // ‚úÖ CANVAS TEXTURE APPROACH
  const forceApplyTextureCanvas = (model: THREE.Object3D) => {
    console.log('ü¶ä Canvas texture approach...');
    
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        console.log(`ü¶ä Canvas texture approach for mesh: ${child.name}`);
        
        try {
          // ‚úÖ LOAD IMAGE AND CREATE CANVAS TEXTURE
          const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
          
          foxAsset.downloadAsync().then(() => {
            console.log('ü¶ä Canvas: Fox.png asset downloaded, creating canvas texture...');
            
            // ‚úÖ CREATE IMAGE ELEMENT
            const img = new Image();
            img.crossOrigin = 'anonymous';
            
            img.onload = () => {
              console.log('ü¶ä Canvas: Image loaded successfully!');
              console.log('ü¶ä Canvas: Image details:', {
                width: img.width,
                height: img.height,
                complete: img.complete
              });
              
              // ‚úÖ CREATE CANVAS TEXTURE
              const canvas = document.createElement('canvas');
              canvas.width = img.width;
              canvas.height = img.height;
              const ctx = canvas.getContext('2d');
              
              if (ctx) {
                ctx.drawImage(img, 0, 0);
                console.log('ü¶ä Canvas: Canvas created with image data');
                
                // ‚úÖ CREATE TEXTURE FROM CANVAS
                const texture = new THREE.CanvasTexture(canvas);
                texture.needsUpdate = true;
      texture.wrapS = THREE.RepeatWrapping;
      texture.wrapT = THREE.RepeatWrapping;
      texture.flipY = false;
                
                // ‚úÖ ENSURE PROPER ENCODING
                // @ts-ignore - encoding property for older Three.js versions
                texture.encoding = THREE.sRGBEncoding;
                texture.format = THREE.RGBAFormat;
                texture.type = THREE.UnsignedByteType;
                
                // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
                child.material.color.setHex(0xffffff);
                child.material.emissive.setHex(0x000000);
                child.material.emissiveIntensity = 0;
                child.material.vertexColors = false;
                
                // ‚úÖ APPLY TEXTURE TO MATERIAL
                child.material.map = texture;
                child.material.map.needsUpdate = true;
                child.material.needsUpdate = true;
                
                // ‚úÖ FORCE RENDER UPDATE FOR iOS
                if (rendererRef.current && sceneRef.current && cameraRef.current) {
                  rendererRef.current.render(sceneRef.current, cameraRef.current);
                  console.log('ü¶ä iOS: Force render update applied!');
                }
                
                // ‚úÖ FORCE RENDER UPDATE FOR iOS
                if (rendererRef.current && sceneRef.current && cameraRef.current) {
                  rendererRef.current.render(sceneRef.current, cameraRef.current);
                  console.log('ü¶ä iOS: Force render update applied!');
                }
                
                // ‚úÖ FORCE MATERIAL UPDATE
                child.material.needsUpdate = true;
                
                console.log('ü¶ä Canvas: Texture applied successfully!');
                console.log('ü¶ä Canvas: Material status:', {
                  hasMap: !!child.material.map,
                  mapNeedsUpdate: child.material.map?.needsUpdate,
                  materialNeedsUpdate: child.material.needsUpdate
                });
                
                // ‚úÖ FORCE RENDER UPDATE
                if (rendererRef.current && sceneRef.current && cameraRef.current) {
                  rendererRef.current.render(sceneRef.current, cameraRef.current);
                  console.log('ü¶ä Canvas: Force render update applied!');
                }
      } else {
                console.error('‚ùå Canvas: Failed to get canvas context');
              }
            };
            
            img.onerror = (error) => {
              console.error('‚ùå Canvas: Failed to load image:', error);
            };
            
            img.src = foxAsset.uri;
          }).catch((error) => {
            console.error('‚ùå Canvas: Failed to download Fox.png asset:', error);
          });
          
    } catch (error) {
          console.error('‚ùå Canvas: Error loading texture:', error);
        }
      }
    });
  };

  // ‚úÖ DATA TEXTURE APPROACH
  const forceApplyTextureData = (model: THREE.Object3D) => {
    console.log('ü¶ä Data texture approach...');
    
    model.traverse((child: any) => {
          if (child.isMesh && child.material) {
        console.log(`ü¶ä Data texture approach for mesh: ${child.name}`);
        
        try {
          // ‚úÖ LOAD IMAGE AND CREATE DATA TEXTURE
          const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
          
          foxAsset.downloadAsync().then(() => {
            console.log('ü¶ä Data: Fox.png asset downloaded, creating data texture...');
            
            // ‚úÖ CREATE IMAGE ELEMENT
            const img = new Image();
            img.crossOrigin = 'anonymous';
            
            img.onload = () => {
              console.log('ü¶ä Data: Image loaded successfully!');
              console.log('ü¶ä Data: Image details:', {
                width: img.width,
                height: img.height,
                complete: img.complete
              });
              
              // ‚úÖ CREATE CANVAS TO GET IMAGE DATA
              const canvas = document.createElement('canvas');
              canvas.width = img.width;
              canvas.height = img.height;
              const ctx = canvas.getContext('2d');
              
              if (ctx) {
                ctx.drawImage(img, 0, 0);
                console.log('ü¶ä Data: Canvas created with image data');
                
                // ‚úÖ GET IMAGE DATA FROM CANVAS
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                console.log('ü¶ä Data: Image data extracted:', {
                  width: imageData.width,
                  height: imageData.height,
                  dataLength: imageData.data.length
                });
                
                // ‚úÖ CREATE DATA TEXTURE FROM IMAGE DATA
                const texture = new THREE.DataTexture(
                  imageData.data,
                  imageData.width,
                  imageData.height,
                  THREE.RGBAFormat
                );
                
                texture.needsUpdate = true;
                texture.wrapS = THREE.RepeatWrapping;
                texture.wrapT = THREE.RepeatWrapping;
                texture.flipY = false;
                
                // ‚úÖ ENSURE PROPER ENCODING
                // @ts-ignore - encoding property for older Three.js versions
                texture.encoding = THREE.sRGBEncoding;
                texture.type = THREE.UnsignedByteType;
                
                // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
                child.material.color.setHex(0xffffff);
                child.material.emissive.setHex(0x000000);
                child.material.emissiveIntensity = 0;
                child.material.vertexColors = false;
                
                // ‚úÖ APPLY TEXTURE TO MATERIAL
                child.material.map = texture;
                child.material.map.needsUpdate = true;
            child.material.needsUpdate = true;
                
                // ‚úÖ FORCE MATERIAL UPDATE
                child.material.needsUpdate = true;
                
                console.log('ü¶ä Data: Texture applied successfully!');
                console.log('ü¶ä Data: Material status:', {
                  hasMap: !!child.material.map,
                  mapNeedsUpdate: child.material.map?.needsUpdate,
                  materialNeedsUpdate: child.material.needsUpdate
                });
                
                // ‚úÖ FORCE RENDER UPDATE
                if (rendererRef.current && sceneRef.current && cameraRef.current) {
                  rendererRef.current.render(sceneRef.current, cameraRef.current);
                  console.log('ü¶ä Data: Force render update applied!');
                }
      } else {
                console.error('‚ùå Data: Failed to get canvas context');
              }
            };
            
            img.onerror = (error) => {
              console.error('‚ùå Data: Failed to load image:', error);
            };
            
            img.src = foxAsset.uri;
          }).catch((error) => {
            console.error('‚ùå Data: Failed to download Fox.png asset:', error);
          });
          
        } catch (error) {
          console.error('‚ùå Data: Error loading texture:', error);
        }
      }
    });
  };

  // ‚úÖ FIXED SYNCHRONOUS TEXTURE LOADING - S·ª¨A L·ªñI ARRAYBUFFER BLOB
  const forceApplyTextureSynchronous = (model: THREE.Object3D) => {
    console.log('ü¶ä Sync: Loading texture with ArrayBuffer fix...');
    
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        console.log(`ü¶ä Sync: Processing mesh: ${child.name}`);
        
        try {
          // ‚úÖ LOAD IMAGE SYNCHRONOUSLY
          const foxAsset = Asset.fromModule(require('../assets/models/Fox.png'));
          
          foxAsset.downloadAsync().then(() => {
            console.log('ü¶ä Sync: Asset downloaded, creating texture...');
            
            // ‚úÖ CREATE IMAGE ELEMENT
            const img = new Image();
            img.crossOrigin = 'anonymous';
            
            // ‚úÖ WAIT FOR IMAGE TO LOAD COMPLETELY
            img.onload = () => {
              console.log('ü¶ä Sync: Image loaded successfully!');
              
              // ‚úÖ WAIT FOR IMAGE TO BE FULLY LOADED
              if (img.complete && img.width > 0 && img.height > 0) {
                console.log('ü¶ä Sync: Image data is fully ready!');
                
                // ‚úÖ CREATE CANVAS TO GET IMAGE DATA
                const canvas = document.createElement('canvas');
                canvas.width = img.width;
                canvas.height = img.height;
                const ctx = canvas.getContext('2d');
                
                if (ctx) {
                  // ‚úÖ DRAW IMAGE TO CANVAS
                  ctx.drawImage(img, 0, 0);
                  console.log('ü¶ä Sync: Canvas created with image data');
                  
                  // ‚úÖ GET IMAGE DATA FROM CANVAS
                  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                  console.log('ü¶ä Sync: Image data extracted, length:', imageData.data.length);
                  
                  // ‚úÖ VERIFY IMAGE DATA HAS CONTENT
                  if (imageData.data.length > 0) {
                    console.log('ü¶ä Sync: Fox.png texture data found, creating texture...');
                    
                    // ‚úÖ VERIFY FOX.PNG TEXTURE DATA
                    const hasValidData = imageData.data.some((value, index) => index % 4 === 0 && value > 0);
                    if (!hasValidData) {
                      console.error('‚ùå Sync: Fox.png texture data is empty or invalid');
                      return;
                    }
                    console.log('ü¶ä Sync: ‚úÖ Fox.png texture data is valid!');
                    
                    // ‚úÖ CREATE DATA TEXTURE FROM FOX.PNG IMAGE DATA
                    const texture = new THREE.DataTexture(
                      imageData.data,
                      imageData.width,
                      imageData.height,
                      THREE.RGBAFormat
                    );
                    
                    // ‚úÖ SETUP FOX.PNG TEXTURE PROPERTIES
                    texture.needsUpdate = true;
                    texture.wrapS = THREE.RepeatWrapping;
                    texture.wrapT = THREE.RepeatWrapping;
                    texture.flipY = false;
                    
                    // ‚úÖ ENSURE PROPER ENCODING FOR FOX.PNG
                    // @ts-ignore - encoding property for older Three.js versions
                    texture.encoding = THREE.sRGBEncoding;
                    texture.type = THREE.UnsignedByteType;
                    
                    console.log('ü¶ä Sync: ‚úÖ Fox.png texture created successfully!');
                    
                    // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
                    child.material.color.setHex(0xffffff);
                    child.material.emissive.setHex(0x000000);
                    child.material.emissiveIntensity = 0;
                    child.material.vertexColors = false;
                    
                    // ‚úÖ APPLY TEXTURE TO MATERIAL
                    child.material.map = texture;
                    child.material.map.needsUpdate = true;
                    child.material.needsUpdate = true;
                    
                    console.log('ü¶ä Sync: ‚úÖ Material connected to Fox.png texture successfully!');
                    
                    // ‚úÖ FORCE RENDER UPDATE
                    if (rendererRef.current && sceneRef.current && cameraRef.current) {
                      rendererRef.current.render(sceneRef.current, cameraRef.current);
                      console.log('ü¶ä Sync: ‚úÖ Fox.png texture rendered successfully!');
                    }
                    
                  } else {
                    console.error('‚ùå Sync: Image data is empty');
                  }
                } else {
                  console.error('‚ùå Sync: Failed to get canvas context');
                }
              } else {
                console.error('‚ùå Sync: Image not fully loaded');
              }
            };
            
            img.onerror = (error) => {
              console.error('‚ùå Sync: Failed to load image:', error);
            };
            
            img.src = foxAsset.uri;
          }).catch((error) => {
            console.error('‚ùå Sync: Failed to download Fox.png asset:', error);
          });
          
        } catch (error) {
          console.error('‚ùå Sync: Error loading texture:', error);
        }
      }
    });
  };

  // ‚úÖ NEW: BYPASS ARRAYBUFFER BLOB ERROR - LOAD TEXTURE DIRECTLY FROM GLTF PARSER
  const forceLoadTextureFromGLTFParser = (model: THREE.Object3D, gltf: any) => {
    console.log('ü¶ä Parser: Loading texture directly from GLTF parser...');
    
    if (!gltf || !gltf.parser) {
      console.error('‚ùå Parser: No GLTF parser available');
      return;
    }
    
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        console.log(`ü¶ä Parser: Processing mesh: ${child.name}`);
        
        try {
          // ‚úÖ ACCESS GLTF PARSER JSON DIRECTLY
          const parser = gltf.parser;
          const json = parser.json;
          
          if (json && json.materials && json.materials.length > 0) {
            const material = json.materials[0];
            console.log('ü¶ä Parser: Found material:', material);
            
            if (material.pbrMetallicRoughness && material.pbrMetallicRoughness.baseColorTexture) {
              const textureIndex = material.pbrMetallicRoughness.baseColorTexture.index;
              console.log('ü¶ä Parser: Texture index:', textureIndex);
              
              if (json.textures && json.textures[textureIndex]) {
                const texture = json.textures[textureIndex];
                console.log('ü¶ä Parser: Found texture:', texture);
                
                if (json.images && json.images[texture.source]) {
                  const image = json.images[texture.source];
                  console.log('ü¶ä Parser: Found image:', image);
                  
                  // ‚úÖ BYPASS SOURCE CACHE ERROR - LOAD DIRECTLY FROM BUFFER
                  if (parser.extensions && parser.extensions.KHR_binary_glTF) {
                    const binaryGLTF = parser.extensions.KHR_binary_glTF;
                    console.log('ü¶ä Parser: Found binary GLTF body');
                    
                    if (binaryGLTF.body && binaryGLTF.body.byteLength > 0) {
                      console.log('ü¶ä Parser: Binary body size:', binaryGLTF.body.byteLength);
                      
                      // ‚úÖ GET BUFFER VIEW FOR IMAGE
                      if (json.bufferViews && json.bufferViews[image.bufferView]) {
                        const bufferView = json.bufferViews[image.bufferView];
                        console.log('ü¶ä Parser: Buffer view:', bufferView);
                        
                        // ‚úÖ EXTRACT IMAGE DATA FROM BUFFER
                        const imageData = new Uint8Array(
                          binaryGLTF.body,
                          bufferView.byteOffset,
                          bufferView.byteLength
                        );
                        
                        console.log('ü¶ä Parser: Extracted image data, length:', imageData.length);
                        
                        // ‚úÖ CREATE TEXTURE FROM EXTRACTED DATA
                        // ‚úÖ FIX: Calculate proper dimensions for PNG data
                        const imageWidth = Math.sqrt(imageData.length / 4); // Approximate square texture
                        const imageHeight = imageWidth;
                        
                        const textureFromBuffer = new THREE.DataTexture(
                          imageData,
                          imageWidth,
                          imageHeight,
                          THREE.RGBAFormat
                        );
                        
                        textureFromBuffer.needsUpdate = true;
                        textureFromBuffer.wrapS = THREE.RepeatWrapping;
                        textureFromBuffer.wrapT = THREE.RepeatWrapping;
                        textureFromBuffer.flipY = false;
                        
                        // ‚úÖ ENSURE PROPER ENCODING
                        // @ts-ignore
                        textureFromBuffer.encoding = THREE.sRGBEncoding;
                        textureFromBuffer.type = THREE.UnsignedByteType;
                        
                        // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
                        child.material.color.setHex(0xffffff);
                        child.material.emissive.setHex(0x000000);
                        child.material.emissiveIntensity = 0;
                        child.material.vertexColors = false;
                        
                        // ‚úÖ APPLY TEXTURE TO MATERIAL
                        child.material.map = textureFromBuffer;
                        child.material.map.needsUpdate = true;
                        child.material.needsUpdate = true;
                        
                        console.log('ü¶ä Parser: ‚úÖ Texture applied from GLTF parser buffer!');
                        
                        // ‚úÖ FORCE RENDER UPDATE
                        if (rendererRef.current && sceneRef.current && cameraRef.current) {
                          rendererRef.current.render(sceneRef.current, cameraRef.current);
                          console.log('ü¶ä Parser: ‚úÖ Texture rendered successfully!');
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        } catch (error) {
          console.error('‚ùå Parser: Error loading texture from GLTF parser:', error);
        }
      }
    });
  };

  // ‚úÖ DEBUG TEXTURE LOADING - ENHANCED FOR FOX.PNG WITH UV MAPPING
  const debugTextureLoading = (model: THREE.Object3D) => {
    console.log('üîç Debugging texture loading for model...');
    console.log('ü¶ä Looking for Fox.png texture rendering with UV mapping...');
    
    model.traverse((child: any) => {
      if (child.isMesh && child.material) {
        console.log(`üé® Mesh: ${child.name}`, {
          materialType: child.material.type,
          hasMap: !!child.material.map,
          hasNormalMap: !!child.material.normalMap,
          hasRoughnessMap: !!child.material.roughnessMap,
          hasMetallicMap: !!child.material.metalnessMap,
          hasAOMap: !!child.material.aoMap,
          hasEmissiveMap: !!child.material.emissiveMap,
          color: child.material.color,
          roughness: child.material.roughness,
          metalness: child.material.metalness,
          transparent: child.material.transparent,
          opacity: child.material.opacity
        });
        
        // ‚úÖ CHECK UV COORDINATES
        if (child.geometry && child.geometry.attributes) {
          const uvAttribute = child.geometry.attributes.uv;
          if (uvAttribute) {
            console.log('‚úÖ UV coordinates found:', {
              count: uvAttribute.count,
              itemSize: uvAttribute.itemSize,
              array: uvAttribute.array?.length || 0
            });
          } else {
            console.log('‚ö†Ô∏è No UV coordinates found for mesh:', child.name);
          }
        }
        
        // ‚úÖ FORCE TEXTURE UPDATE
        if (child.material.map) {
          child.material.map.needsUpdate = true;
          console.log('‚úÖ Base texture map updated');
          console.log('ü¶ä Fox.png texture should be visible now!');
          
          // ‚úÖ LOG TEXTURE DETAILS
          console.log('ü¶ä Texture details:', {
            image: child.material.map.image,
            width: child.material.map.image?.width,
            height: child.material.map.image?.height,
            format: child.material.map.format,
            type: child.material.map.type,
            wrapS: child.material.map.wrapS,
            wrapT: child.material.map.wrapT,
            minFilter: child.material.map.minFilter,
            magFilter: child.material.map.magFilter
          });
        } else {
          console.log('‚ö†Ô∏è No texture map found - attempting force load...');
          // ‚úÖ FORCE LOAD FOX.PNG IF NO TEXTURE FOUND - ASYNC CALL
          forceLoadFoxTexture(model).catch(err => {
            console.error('Failed to load Fox texture:', err);
          });
        }
        
        if (child.material.normalMap) {
          child.material.normalMap.needsUpdate = true;
          console.log('‚úÖ Normal map updated');
        }
        
        if (child.material.roughnessMap) {
          child.material.roughnessMap.needsUpdate = true;
          console.log('‚úÖ Roughness map updated');
        }
        
        if (child.material.metalnessMap) {
          child.material.metalnessMap.needsUpdate = true;
          console.log('‚úÖ Metallic map updated');
        }
        
        // ‚úÖ LOG COLOR RENDERING
        console.log('ü¶ä Color rendering info:', {
          baseColor: child.material.color,
          emissive: child.material.emissive,
          emissiveIntensity: child.material.emissiveIntensity,
          envMapIntensity: child.material.envMapIntensity,
          combine: child.material.combine
        });
      }
    });
  };

  // ‚úÖ TC3.1: RAYCASTING FOR TOUCH ANIMATION TRIGGER
  const performRaycasting = (touchX: number, touchY: number, screenWidth: number, screenHeight: number) => {
    if (!modelRef.current || !cameraRef.current || !rendererRef.current) return null;

    // Convert screen coordinates to normalized device coordinates (-1 to +1)
    const mouse = new THREE.Vector2();
    mouse.x = (touchX / screenWidth) * 2 - 1;
    mouse.y = -(touchY / screenHeight) * 2 + 1;

    // Create raycaster
    const raycaster = new THREE.Raycaster();
    raycaster.setFromCamera(mouse, cameraRef.current);

    // Check intersection with model
    const intersects = raycaster.intersectObject(modelRef.current, true);

    if (intersects.length > 0) {
      console.log('üéØ Model touched! Triggering animation...');
      return intersects[0];
    }
    return null;
  };

  // ‚úÖ TC3.1: TRIGGER ANIMATION ON TOUCH
  const triggerTouchAnimation = (animationName: string = 'hit') => {
    if (!mixerRef.current || !modelRef.current) return;

    const anyModel = modelRef.current as any;
    const clips = anyModel.animations || [];

    if (clips.length > 0) {
      // Find animation clip
      const clip = clips.find((c: any) =>
        c.name?.toLowerCase().includes(animationName.toLowerCase())
      ) || clips[Math.floor(Math.random() * clips.length)]; // Random if not found

      // Stop current action and play new one
      mixerRef.current.stopAllAction();
      const action = mixerRef.current.clipAction(clip);
      action.reset();
      action.setLoop(THREE.LoopOnce, 1);
      action.clampWhenFinished = true;
      action.play();

      setCurrentAnimation(animationName);
      setAnimationFeedback(`üéØ ${animationName.toUpperCase()}!`);
      console.log(`üé¨ Playing touch animation: ${clip.name || animationName}`);

      // Clear feedback after short time
      setTimeout(() => setAnimationFeedback(''), 1000);

      // Return to idle after animation
      setTimeout(() => {
        if (mixerRef.current) {
          const idleClip = clips.find((c: any) => c.name?.toLowerCase().includes('idle')) || clips[0];
          const idleAction = mixerRef.current.clipAction(idleClip);
          idleAction.reset();
          idleAction.play();
          setCurrentAnimation('idle');
        }
      }, clip.duration * 1000 || 2000);
    }
  };

  // ‚úÖ TC3.2: SWIPE GESTURE DETECTION AND THROW ANIMATION
  const detectSwipeGesture = (startX: number, startY: number, endX: number, endY: number, duration: number) => {
    const deltaX = endX - startX;
    const deltaY = endY - startY;
    const distance = Math.sqrt(deltaX * deltaX + deltaY * deltaY);
    const velocity = distance / duration; // pixels per ms

    // Swipe thresholds
    const minDistance = 100; // minimum swipe distance
    const minVelocity = 0.5; // minimum swipe velocity

    if (distance > minDistance && velocity > minVelocity) {
      // Determine swipe direction
      const angle = Math.atan2(deltaY, deltaX);
      const direction = {
        horizontal: Math.abs(deltaX) > Math.abs(deltaY),
        vertical: Math.abs(deltaY) > Math.abs(deltaX),
        right: deltaX > 0,
        left: deltaX < 0,
        up: deltaY < 0,
        down: deltaY > 0
      };

      console.log(`üèê Swipe detected! Distance: ${distance.toFixed(2)}, Velocity: ${velocity.toFixed(2)}, Direction:`, direction);

      // Trigger throw animation based on direction
      if (direction.horizontal) {
        triggerThrowAnimation(direction.right ? 'throw_right' : 'throw_left', velocity);
      } else if (direction.vertical) {
        triggerThrowAnimation(direction.up ? 'throw_up' : 'throw_down', velocity);
      }

      return true;
    }
    return false;
  };

  // ‚úÖ TC3.2: TRIGGER THROW ANIMATION
  const triggerThrowAnimation = (throwType: string, velocity: number) => {
    if (!mixerRef.current || !modelRef.current) return;

    const anyModel = modelRef.current as any;
    const clips = anyModel.animations || [];

    if (clips.length > 0) {
      // Find throw animation or use attack/fly animation
      const throwClip = clips.find((c: any) =>
        c.name?.toLowerCase().includes('attack') ||
        c.name?.toLowerCase().includes('fly') ||
        c.name?.toLowerCase().includes('jump')
      ) || clips[Math.floor(Math.random() * clips.length)];

      // Stop current action and play throw animation
      mixerRef.current.stopAllAction();
      const action = mixerRef.current.clipAction(throwClip);
      action.reset();
      action.setLoop(THREE.LoopOnce, 1);
      action.clampWhenFinished = true;

      // Adjust playback speed based on swipe velocity
      const speedMultiplier = Math.min(Math.max(velocity / 2, 0.5), 3.0);
      action.setEffectiveTimeScale(speedMultiplier);
      action.play();

      setCurrentAnimation(throwType);
      setAnimationFeedback(`üèê ${throwType.replace('_', ' ').toUpperCase()}!`);
      console.log(`üé¨ Playing throw animation: ${throwClip.name || throwType} (speed: ${speedMultiplier.toFixed(2)}x)`);

      // Clear feedback after animation
      setTimeout(() => setAnimationFeedback(''), 1500);

      // Add visual feedback - temporary scale effect
      if (modelRef.current) {
        const originalScale = (modelRef.current as any).originalScale || 0.6;
        const scaleEffect = originalScale * (1 + velocity * 0.1);
        modelRef.current.scale.setScalar(scaleEffect);

        // Return to normal scale
        setTimeout(() => {
          if (modelRef.current) {
            modelRef.current.scale.setScalar(originalScale);
          }
        }, 200);
      }

      // Return to idle after animation
      setTimeout(() => {
        if (mixerRef.current) {
          const idleClip = clips.find((c: any) => c.name?.toLowerCase().includes('idle')) || clips[0];
          const idleAction = mixerRef.current.clipAction(idleClip);
          idleAction.reset();
          idleAction.play();
          setCurrentAnimation('idle');
        }
      }, (throwClip.duration * 1000 / speedMultiplier) || 1500);
    }
  };

  // ‚úÖ TOUCH HANDLERS ƒê√É ƒê∆Ø·ª¢C THAY TH·∫æ B·∫∞NG PANRESPONDER

  const onHandlerStateChange = (event: any) => {
    if (event.nativeEvent.state === State.END) {
      if (modelRef.current) {
        const { velocityX } = event.nativeEvent;
        const momentum = velocityX * 0.001; // ‚úÖ MOMENTUM M∆Ø·ª¢T M√Ä CHO 360 ƒê·ªò

        // ‚úÖ TH√äM MOMENTUM SAU KHI TH·∫¢ TAY
        modelRef.current.rotation.y += momentum;

        // ‚úÖ RESET FLAG SAU 2 GI√ÇY
        setTimeout(() => {
          if (modelRef.current) {
            (modelRef.current as any).isUserRotating = false;
            // console.log(`üîÑ Auto rotation resumed`); // ‚ùå B·ªöT LOG
          }
        }, 2000);

        // console.log(`üöÄ Momentum applied: ${momentum}, Final rotation: ${modelRef.current.rotation.y}`); // ‚ùå B·ªöT LOG
      }
    }
  };

  useEffect(() => {
    requestCameraPermission();

    // ‚úÖ PRELOAD MODELS NGAY KHI KH·ªûI ƒê·ªòNG APP
    preloadModels();

    // ‚úÖ KH√îNG AUTO-HIDE NGAY - CH·ªú MODEL LOAD XONG
    // Auto-hide s·∫Ω ƒë∆∞·ª£c set trong loadPokemonModel

    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
      // ‚úÖ KH√îNG CLEAR HINT TIMEOUT ·ªû ƒê√ÇY N·ªÆA
    };
  }, []);

  // ‚úÖ PRELOAD MODELS FOR INSTANT LOADING
  const preloadModels = async () => {
    try {
      console.log('‚ö° Preloading models for instant access...');

      // ‚úÖ PRELOAD SCIZOR MODEL - DIRECT LOADING
      try {
        const scizorModuleId = require('../assets/models/pokemon_scizor.glb');
        console.log('‚úÖ Scizor model preloaded! ModuleId:', scizorModuleId);
      } catch (error) {
        console.log('‚ö†Ô∏è Scizor preload failed:', error);
      }

      // ‚úÖ PRELOAD FOX MODEL - DIRECT LOADING
      try {
        const foxModuleId = require('../assets/models/Fox.glb');
        console.log('‚úÖ Fox model preloaded! ModuleId:', foxModuleId);
      } catch (error) {
        console.log('‚ö†Ô∏è Fox preload failed:', error);
      }

      // ‚úÖ PRELOAD FOX.PNG TEXTURE
      try {
        const foxTextureAsset = Asset.fromModule(require('../assets/models/Fox.png'));
        await foxTextureAsset.downloadAsync();
        console.log('‚úÖ Fox.png texture preloaded! URI:', foxTextureAsset.uri);
      } catch (error) {
        console.log('‚ö†Ô∏è Fox.png texture preload failed:', error);
      }

    } catch (error) {
      console.log('‚ö†Ô∏è Preload failed, will load on demand:', error);
    }
  };

  const requestCameraPermission = async () => {
    const { status } = await Camera.requestCameraPermissionsAsync();
    setHasPermission(status === 'granted');
    console.log('üì∑ Camera permission:', status === 'granted' ? 'GRANTED' : 'DENIED');
  };


  // Handle QR Code scan
  const handleBarCodeScanned = ({ type, data }: { type: string; data: string }) => {
    console.log('üéØ QR Code scanned successfully:', data);
    setScannedData(data);
    loadPokemonModel(data);
  };

  // ‚úÖ DYNAMIC SCALE SYSTEM - H·ªÜ TH·ªêNG SCALE T·ª∞ ƒê·ªòNG
  const calculateOptimalScale = (model: THREE.Object3D) => {
    console.log('üìê Calculating optimal scale for model...');
    
    // ‚úÖ B∆Ø·ªöC 1: L·∫§Y K√çCH TH∆Ø·ªöC MODEL (BOUNDING BOX)
    const box = new THREE.Box3().setFromObject(model);
          const size = box.getSize(new THREE.Vector3());
          const maxDimension = Math.max(size.x, size.y, size.z);

          console.log('üìè Model bounding box:', {
            width: size.x,
            height: size.y,
            depth: size.z,
            maxDimension: maxDimension
          });

    // ‚úÖ B∆Ø·ªöC 2: T√çNH SCALE D·ª∞A TR√äN M√ÄN H√åNH
    const screenHeight = Dimensions.get('window').height;
    const screenWidth = Dimensions.get('window').width;
    const aspectRatio = screenWidth / screenHeight;
    
          // ‚úÖ M·ª§C TI√äU: MODEL CHI·∫æM 100% K√çCH TH∆Ø·ªöC T·ª∞ NHI√äN
          const targetScreenSize = 2.0; // 200% - gi·∫£m k√≠ch th∆∞·ªõc ƒë·ªÉ model v·ª´a ph·∫£i
          const optimalScale = targetScreenSize / maxDimension;

    // ‚úÖ DEBUG: SCALE CALCULATION
    console.log('üéØ Scale calculation:', {
            targetScreenSize,
            maxDimension,
      calculatedScale: optimalScale,
      screenSize: { width: screenWidth, height: screenHeight, aspectRatio }
    });
    
          // ‚úÖ B∆Ø·ªöC 3: √ÅP D·ª§NG SCALE V√Ä SETUP ZOOM LIMITS
          model.scale.setScalar(optimalScale);
          model.position.set(0, -0.1, 0);
          
          // ‚úÖ DEBUG: LOG SCALE CU·ªêI C√ôNG
          console.log('üéØ Final scale applied:', {
            scale: model.scale,
            position: model.position,
            boundingBox: { width: size.x, height: size.y, depth: size.z }
          });
          
          // ‚úÖ STORE SCALE INFO FOR ZOOM LIMITS
          (model as any).originalScale = optimalScale;
          (model as any).minScale = optimalScale * 0.5;  // ‚úÖ MIN: 50% c·ªßa original
          (model as any).maxScale = optimalScale * 3.0;  // ‚úÖ MAX: 300% c·ªßa original
    
    console.log('‚úÖ Dynamic scale applied:', {
      originalScale: optimalScale,
      minScale: optimalScale * 0.5,
      maxScale: optimalScale * 3.0,
      position: model.position
    });
    
    return optimalScale;
  };

  // ‚úÖ SIMPLIFIED MODEL LOADING - CH·ªà LOAD MODEL TH·∫¨T, KH√îNG FALLBACK
  const loadPokemonModel = async (qrData: string) => {
    try {
      console.log('üéØ Starting REAL model loading for:', qrData);
      setIsLoading(true);
      setLoadingProgress(10);
      setModelInfo('ƒêang ph√¢n t√≠ch QR code...');

      // Parse QR data ƒë·ªÉ l·∫•y model config
      const glbConfig = getGLBModelFromQRData(qrData);

      if (glbConfig) {
        console.log('‚úÖ Model config found:', glbConfig.name, 'File:', glbConfig.filePath);
        setModelInfo(`ü¶ä ƒêang t·∫£i model GLB: ${glbConfig.name}...`);
        setLoadingProgress(30);

        // ‚úÖ SIMPLIFIED MODEL LOADING - DIRECT APPROACH
        console.log('üéØ Using simplified model loading approach');
          setLoadingProgress(40);
          setModelInfo(`üì• ƒêang t·∫£i file GLB: ${glbConfig.name}...`);

        let asset: any;
        let gltf: any;

        try {
          // ‚úÖ SIMPLE ASSET LOADING
          console.log('üîç Loading asset for:', glbConfig.filePath);

            if (glbConfig.filePath === 'assets/models/pokemon_scizor.glb') {
            asset = Asset.fromModule(require('../assets/models/pokemon_scizor.glb'));
            } else if (glbConfig.filePath === 'assets/models/Fox.glb') {
            asset = Asset.fromModule(require('../assets/models/Fox.glb'));
                  } else {
              throw new Error(`Unknown model filePath: ${glbConfig.filePath}`);
            }

          console.log('‚úÖ Asset created:', asset.uri);
            await asset.downloadAsync();
          console.log('‚úÖ Asset downloaded');

          // ‚úÖ SIMPLE GLTF LOADING
            gltf = await loadAsync(asset);
          console.log('‚úÖ GLTF loaded successfully');
          
          // ‚úÖ DEBUG: KI·ªÇM TRA GLTF LOADER RESULT
          console.log('üîç GLTF Loader Result:');
          console.log('  - gltf type:', typeof gltf);
          console.log('  - gltf keys:', Object.keys(gltf));
          console.log('  - gltf.scene type:', typeof gltf.scene);
          console.log('  - gltf.scene children:', gltf.scene?.children?.length || 0);
          console.log('ü¶ä GLTF structure:', {
            scene: !!gltf.scene,
            animations: gltf.animations?.length || 0,
            scenes: gltf.scenes?.length || 0,
            materials: gltf.materials?.length || 0,
            textures: gltf.textures?.length || 0,
            images: gltf.images?.length || 0
          });
          
          // ‚úÖ DEBUG: KI·ªÇM TRA CHI TI·∫æT GLTF STRUCTURE
          console.log('üîç GLTF Debug - Materials:', gltf.materials);
          console.log('üîç GLTF Debug - Textures:', gltf.textures);
          console.log('üîç GLTF Debug - Images:', gltf.images);
          
          // ‚úÖ DEBUG: KI·ªÇM TRA GLTF STRUCTURE CHI TI·∫æT
          console.log('üîç GLTF Structure Analysis:');
          console.log('  - Scene:', !!gltf.scene);
          console.log('  - Materials count:', gltf.materials?.length || 0);
          console.log('  - Textures count:', gltf.textures?.length || 0);
          console.log('  - Images count:', gltf.images?.length || 0);
          console.log('  - Animations count:', gltf.animations?.length || 0);
          
          // ‚úÖ DEBUG: KI·ªÇM TRA GLTF PARSER SOURCE CACHE ERROR
          if (gltf.parser && gltf.parser.sourceCache) {
            console.log('üîç GLTF Parser Source Cache Error:');
            console.log('  - sourceCache:', gltf.parser.sourceCache);
            console.log('  - ArrayBuffer blob error detected - using bypass method');
          }

          if (!gltf || !gltf.scene) {
            throw new Error('GLB file loaded but no scene found');
          }

          const loadedModel = gltf.scene;
          console.log('üéâ MODEL LOADED!', {
            children: loadedModel.children?.length || 0,
            animations: gltf.animations?.length || 0
          });

          // ‚úÖ SIMPLE MODEL SETUP
          console.log('üîß Setting up model...');
          
          // ‚úÖ SCALE WILL BE CALCULATED BY calculateOptimalScale() LATER
          
          console.log('‚úÖ Model setup complete');

          // ‚úÖ PROPER UV MAPPING SETUP - TU√ÇN THEO NGUY√äN T·∫ÆC UV MAPPING
          console.log('üé® Setting up materials with proper UV mapping...');
          console.log('ü¶ä Setting up Fox.png texture rendering with UV mapping...');
          
          // ‚úÖ B∆Ø·ªöC 1: KI·ªÇM TRA GLTF STRUCTURE CHO UV MAPPING
          console.log('üó∫Ô∏è Checking GLTF structure for UV mapping...');
          console.log('ü¶ä GLTF structure:', {
            textures: gltf.textures?.length || 0,
            materials: gltf.materials?.length || 0,
            images: gltf.images?.length || 0,
            scenes: gltf.scenes?.length || 0
          });
          
          // ‚úÖ B∆Ø·ªöC 2: KI·ªÇM TRA UV COORDINATES (TEXCOORD_0) - TRI·ªÇN KHAI THEO LU·ªíNG CHU·∫®N
          console.log('üîç GLTF Scene Children Analysis:');
          console.log('  - Scene children count:', gltf.scene?.children?.length || 0);
          console.log('  - Scene children:', gltf.scene?.children);

              loadedModel.traverse((child: any) => {
            if (child.isMesh) {
              child.castShadow = true;
              child.receiveShadow = true;

              console.log(`üó∫Ô∏è Checking UV mapping for mesh: ${child.name}`);
              
              // ‚úÖ KI·ªÇM TRA UV COORDINATES
              if (child.geometry && child.geometry.attributes) {
                const uvAttribute = child.geometry.attributes.uv;
                if (uvAttribute) {
                  console.log('‚úÖ UV coordinates found:', {
                    count: uvAttribute.count,
                    itemSize: uvAttribute.itemSize,
                    array: uvAttribute.array?.length || 0
                  });
                      } else {
                  console.log('‚ö†Ô∏è No UV coordinates found for mesh:', child.name);
                }
              }
              
              // ‚úÖ DEBUG: KI·ªÇM TRA MATERIAL T·ª™ GLTF THEO QUY T·∫ÆC PBR
              console.log('üîç Material debug:', {
                materialType: child.material.type,
                hasMap: !!child.material.map,
                materialName: child.material.name,
                materialId: child.material.id
              });
              
              // ‚úÖ DEBUG: KI·ªÇM TRA PBR MATERIAL PROPERTIES
              if (child.material.pbrMetallicRoughness) {
                console.log('üîç PBR Material properties:', {
                  baseColorTexture: child.material.pbrMetallicRoughness.baseColorTexture,
                  metallicFactor: child.material.pbrMetallicRoughness.metallicFactor,
                  roughnessFactor: child.material.pbrMetallicRoughness.roughnessFactor
                });
              }
              
            if (child.material) {
                // ‚úÖ FORCE MATERIAL UPDATE
                        child.material.needsUpdate = true;
                console.log(`ü¶ä Processing material for mesh: ${child.name}`);
                
                // ‚úÖ DEBUG: KI·ªÇM TRA MATERIAL NGAY L·∫¶N ƒê·∫¶U
                console.log('üîç Material First Load Debug:');
                console.log('  - Material name:', child.material.name);
                console.log('  - Material type:', child.material.type);
                console.log('  - Has map:', !!child.material.map);
                console.log('  - Material color:', child.material.color);
                console.log('  - Material emissive:', child.material.emissive);
                console.log('  - Material emissiveIntensity:', child.material.emissiveIntensity);
                
                // ‚úÖ DISABLE FALLBACK COLOR - FORCE TEXTURE USAGE
                child.material.color.setHex(0xffffff); // Set to white to avoid color interference
                child.material.emissive.setHex(0x000000); // No emissive color
                child.material.emissiveIntensity = 0; // No emissive intensity
                
                // ‚úÖ FORCE DISABLE ALL FALLBACK COLORS
                child.material.vertexColors = false; // Disable vertex colors
                child.material.wireframe = false; // Disable wireframe
                child.material.transparent = false; // Disable transparency
                child.material.opacity = 1.0; // Full opacity
                
                // ‚úÖ FORCE MATERIAL TO USE TEXTURE ONLY
                child.material.map = null; // Clear any existing map first
                    child.material.needsUpdate = true;
                
                // ‚úÖ B∆Ø·ªöC 3: KI·ªÇM TRA TEXTURE T·ª™ GLTF - TRI·ªÇN KHAI THEO LU·ªíNG CHU·∫®N
                if (child.material.map) {
                  child.material.map.needsUpdate = true;
                  console.log('‚úÖ Texture map found and updated for mesh:', child.name);
                  console.log('ü¶ä Fox.png texture should be visible!');
                  
                  // ‚úÖ LOG TEXTURE INFO
                  console.log('ü¶ä Texture info:', {
                    image: child.material.map.image,
                    width: child.material.map.image?.width,
                    height: child.material.map.image?.height,
                    format: child.material.map.format,
                    type: child.material.map.type,
                    wrapS: child.material.map.wrapS,
                    wrapT: child.material.map.wrapT
                                });
              } else {
                  // ‚úÖ DEBUG: KI·ªÇM TRA TEXTURE LOADING NGAY L·∫¶N ƒê·∫¶U
                  console.log('üîç Texture First Load Debug:');
                  console.log('  - No texture map found for mesh:', child.name);
                  console.log('  - Material has map:', !!child.material.map);
                  console.log('  - Material needsUpdate:', child.material.needsUpdate);
                  console.log('‚ö†Ô∏è No texture map found for mesh:', child.name);
                  console.log('ü¶ä Attempting to load texture from GLTF structure...');
                  
                  // ‚úÖ B∆Ø·ªöC 4: LOAD TEXTURE T·ª™ GLTF STRUCTURE - TRI·ªÇN KHAI THEO LU·ªíNG CHU·∫®N
                // ‚úÖ DEBUG: KI·ªÇM TRA GLTF PARSER TEXTURE LOADING
                console.log('üîç GLTF Parser Texture Loading Debug:');
                console.log('  - gltf.textures:', gltf.textures);
                console.log('  - gltf.images:', gltf.images);
                console.log('  - gltf.materials:', gltf.materials);
                
                // ‚úÖ FORCE LOAD TEXTURE T·ª™ GLTF PARSER
                if (gltf.parser && gltf.parser.textureCache) {
                  console.log('üîç Force loading texture from GLTF parser...');
                  const textureCache = gltf.parser.textureCache;
                  const textureKeys = Object.keys(textureCache);
                  console.log('  - textureCache keys:', textureKeys);
                  
                  if (textureKeys.length > 0) {
                    const textureKey = textureKeys[0];
                    const textureData = textureCache[textureKey];
                    console.log('  - textureData:', textureData);
                    
                    if (textureData && textureData._j) {
                      console.log('  - Found texture in cache, applying...');
                      child.material.map = textureData._j;
                      child.material.map.needsUpdate = true;
                      child.material.needsUpdate = true;
                      console.log('‚úÖ Texture applied from GLTF parser cache!');
                    }
                  }
                }
                
                // ‚úÖ FORCE LOAD TEXTURE T·ª™ GLTF PARSER JSON
                if (gltf.parser && gltf.parser.json) {
                  console.log('üîç Force loading texture from GLTF parser JSON...');
                  const json = gltf.parser.json;
                  console.log('  - JSON materials:', json.materials);
                  console.log('  - JSON textures:', json.textures);
                  console.log('  - JSON images:', json.images);
                  
                  if (json.materials && json.materials.length > 0) {
                    const material = json.materials[0];
                    console.log('  - Material:', material);
                    
                    if (material.pbrMetallicRoughness && material.pbrMetallicRoughness.baseColorTexture) {
                      const textureIndex = material.pbrMetallicRoughness.baseColorTexture.index;
                      console.log('  - Texture index:', textureIndex);
                      
                      if (json.textures && json.textures[textureIndex]) {
                        const texture = json.textures[textureIndex];
                        console.log('  - Texture:', texture);
                        
                        if (json.images && json.images[texture.source]) {
                          const image = json.images[texture.source];
                          console.log('  - Image:', image);
                          
                          // ‚úÖ T·∫†O TEXTURE T·ª™ GLTF PARSER JSON
                          console.log('  - Creating texture from GLTF parser JSON...');
                          const textureFromJSON = new THREE.Texture();
                          textureFromJSON.needsUpdate = true;
                          textureFromJSON.wrapS = THREE.RepeatWrapping;
                          textureFromJSON.wrapT = THREE.RepeatWrapping;
                          textureFromJSON.flipY = false;
                          
                          // ‚úÖ FORCE LOAD IMAGE DATA T·ª™ GLTF PARSER
                          console.log('  - Force loading image data from GLTF parser...');
                          if (gltf.parser && gltf.parser.sourceCache) {
                            const sourceCache = gltf.parser.sourceCache;
                            const sourceKeys = Object.keys(sourceCache);
                            console.log('  - sourceCache keys:', sourceKeys);
                            
                            if (sourceKeys.length > 0) {
                              const sourceKey = sourceKeys[0];
                              const sourceData = sourceCache[sourceKey];
                              console.log('  - sourceData:', sourceData);
                              
                              if (sourceData && sourceData._j) {
                                console.log('  - Found image data in source cache, applying...');
                                textureFromJSON.image = sourceData._j;
                                textureFromJSON.needsUpdate = true;
                                console.log('‚úÖ Image data applied from GLTF parser source cache!');
                              }
                            }
                          }
                          
                          // ‚úÖ FORCE LOAD IMAGE DATA T·ª™ GLTF PARSER BUFFER
                          console.log('  - Force loading image data from GLTF parser buffer...');
                          if (gltf.parser && gltf.parser.json && gltf.parser.json.buffers) {
                            const buffers = gltf.parser.json.buffers;
                            console.log('  - buffers:', buffers);
                            
                            if (buffers && buffers.length > 0) {
                              const buffer = buffers[0];
                              console.log('  - buffer:', buffer);
                              
                              if (buffer.byteLength > 0) {
                                console.log('  - Found buffer data, creating image...');
                                const imageData = new Uint8Array(buffer.byteLength);
                                textureFromJSON.image = imageData;
                                textureFromJSON.needsUpdate = true;
                                console.log('‚úÖ Image data created from GLTF parser buffer!');
                              }
                            }
                          }
                          
                          // ‚úÖ FORCE LOAD IMAGE DATA T·ª™ GLTF PARSER EXTENSIONS
                          console.log('  - Force loading image data from GLTF parser extensions...');
                          if (gltf.parser && gltf.parser.extensions && gltf.parser.extensions.KHR_binary_glTF) {
                            const binaryGLTF = gltf.parser.extensions.KHR_binary_glTF;
                            console.log('  - binaryGLTF:', binaryGLTF);
                            
                            if (binaryGLTF.body && binaryGLTF.body.byteLength > 0) {
                              console.log('  - Found binary GLTF body, creating image...');
                              const imageData = new Uint8Array(binaryGLTF.body);
                              textureFromJSON.image = imageData;
                              textureFromJSON.needsUpdate = true;
                              console.log('‚úÖ Image data created from GLTF parser binary body!');
                            }
                          }
                          
                          child.material.map = textureFromJSON;
                          child.material.needsUpdate = true;
                          console.log('‚úÖ Texture created from GLTF parser JSON!');
                        }
                      }
                    }
                  }
                }
                
                            if (gltf.textures && gltf.textures.length > 0) {
                    console.log('ü¶ä Found textures in GLTF, applying to material...');
                    const texture = gltf.textures[0];
                    
                                if (texture && texture.image) {
                      console.log('ü¶ä Applying texture from GLTF structure...');
                      
                      // ‚úÖ FORCE CLEAR MATERIAL COLOR FIRST
                      child.material.color.setHex(0xffffff);
                      child.material.emissive.setHex(0x000000);
                      child.material.emissiveIntensity = 0;
                      child.material.vertexColors = false;
                      
                    child.material.map = texture;
                      child.material.map.needsUpdate = true;
                    child.material.needsUpdate = true;

                      // ‚úÖ ENSURE PROPER UV MAPPING SETTINGS
                                    child.material.map.wrapS = THREE.RepeatWrapping;
                                    child.material.map.wrapT = THREE.RepeatWrapping;
                                    child.material.map.flipY = false;

                      console.log('‚úÖ Texture applied with proper UV mapping!');
          } else {
                      console.log('‚ö†Ô∏è Texture from GLTF has no image');
          }
        } else {
                    console.log('‚ö†Ô∏è No textures found in GLTF structure');
                    
                    // ‚úÖ FORCE LOAD TEXTURE T·ª™ GLTF STRUCTURE
                    console.log('ü¶ä Force loading texture from GLTF structure...');
                    if (gltf.images && gltf.images.length > 0) {
                      const image = gltf.images[0];
                      console.log('ü¶ä Found image in GLTF:', {
                        mimeType: image.mimeType,
                        bufferView: image.bufferView,
                        hasImage: !!image.image
                      });
                      
                      if (image.image) {
                        console.log('ü¶ä Creating texture from GLTF image...');
                        const texture = new THREE.Texture(image.image);
                      texture.needsUpdate = true;
                      texture.wrapS = THREE.RepeatWrapping;
                      texture.wrapT = THREE.RepeatWrapping;
                      texture.flipY = false;

                    child.material.map = texture;
                    child.material.needsUpdate = true;
                        
                        console.log('‚úÖ Texture created from GLTF image!');
                      }
                    }
                  }
                }
                
                // ‚úÖ ENABLE NORMAL MAP IF EXISTS
                if (child.material.normalMap) {
                  child.material.normalMap.needsUpdate = true;
                  console.log('‚úÖ Normal map found for mesh:', child.name);
                }
                
                // ‚úÖ ENABLE ROUGHNESS MAP IF EXISTS
                if (child.material.roughnessMap) {
                  child.material.roughnessMap.needsUpdate = true;
                  console.log('‚úÖ Roughness map found for mesh:', child.name);
                }
                
                // ‚úÖ ENABLE METALLIC MAP IF EXISTS
                if (child.material.metalnessMap) {
                  child.material.metalnessMap.needsUpdate = true;
                  console.log('‚úÖ Metallic map found for mesh:', child.name);
                }
                
                console.log('‚úÖ Material updated for mesh:', child.name, {
                  hasMap: !!child.material.map,
                  hasNormalMap: !!child.material.normalMap,
                  hasRoughnessMap: !!child.material.roughnessMap,
                  hasMetallicMap: !!child.material.metalnessMap
                });
                
                // ‚úÖ LOG COLOR INFO
                console.log('ü¶ä Color info:', {
                  baseColor: child.material.color,
                  emissive: child.material.emissive,
                  emissiveIntensity: child.material.emissiveIntensity
                });
                              }
                            }
                          });

          // ‚úÖ SIMPLE ANIMATION SETUP
          if (gltf.animations && gltf.animations.length > 0) {
            console.log('üé¨ Setting up animations...');
            mixerRef.current = new THREE.AnimationMixer(loadedModel);
            
            const firstClip = gltf.animations[0];
            const action = mixerRef.current.clipAction(firstClip);
            action.play();
            console.log('‚úÖ Animation setup complete');
          }

          // ‚úÖ ADD MODEL TO SCENE - SIMPLIFIED
          console.log('üéØ Adding model to scene...');
          
          if (sceneRef.current) {
            // Clear existing models
            sceneRef.current.clear();
            
            // Add lighting back
            const ambientLight = new THREE.AmbientLight(0x404040, 0.6);
            sceneRef.current.add(ambientLight);
            
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(1, 1, 1);
            sceneRef.current.add(directionalLight);
            
            // Add model to scene
            sceneRef.current.add(loadedModel);
            modelRef.current = loadedModel;
            console.log('ü¶ä Model added to scene - Fox.png should be visible!');
            
            // ‚úÖ DEBUG: KI·ªÇM TRA RENDER NGAY L·∫¶N ƒê·∫¶U
            console.log('üîç Render First Load Debug:');
            console.log('  - Model added to scene');
            console.log('  - Scene children count:', sceneRef.current.children.length);
            console.log('  - Model position:', loadedModel.position);
            console.log('  - Model scale:', loadedModel.scale);
            console.log('  - Model rotation:', loadedModel.rotation);
            
            // ‚úÖ APPLY DYNAMIC SCALE SYSTEM
            console.log('üìê Applying dynamic scale system...');
            calculateOptimalScale(loadedModel);
            
            // ‚úÖ DEBUG TEXTURE LOADING - CHI TI·∫æT H∆†N
            console.log('üîç Debugging texture loading...');
            
            // ‚úÖ KI·ªÇM TRA NGAY L·∫¨P T·ª®C SAU KHI LOAD
            console.log('ü¶ä === KI·ªÇM TRA TEXTURE NGAY SAU KHI LOAD ===');
            loadedModel.traverse((child: any) => {
              if (child.isMesh && child.material) {
                console.log(`ü¶ä Mesh: ${child.name}`);
                console.log(`  - Has texture map:`, !!child.material.map);
                console.log(`  - Material type:`, child.material.type);
                console.log(`  - Material color:`, child.material.color);
                console.log(`  - Material emissive:`, child.material.emissive);
                
                if (child.material.map) {
                  console.log(`  - Texture image:`, child.material.map.image);
                  console.log(`  - Texture width:`, child.material.map.image?.width);
                  console.log(`  - Texture height:`, child.material.map.image?.height);
                }
              }
            });
            
            debugTextureLoading(loadedModel);
            
            // ‚úÖ FORCE FIX TEXTURE - ASYNC
            console.log('ü¶ä Force fixing texture from GLB...');
            forceLoadFoxTexture(loadedModel).then(() => {
              console.log('‚úÖ Texture fixed successfully!');
            }).catch(err => {
              console.error('‚ùå Failed to fix texture:', err);
            });
                  
                  // ‚úÖ REMOVED OLD TEXTURE LOADING METHODS - USING NEW ASYNC METHOD ONLY

            // ‚úÖ SHOW GESTURE HINT KHI MODEL LOAD XONG
            console.log('üéØ Showing gesture hint for loaded model');
            setShowGestureHint(true);
            console.log('üéØ showGestureHint set to true');
            
            // ‚úÖ FORCE RE-RENDER ƒê·ªÇ ƒê·∫¢M B·∫¢O UI UPDATE
            setTimeout(() => {
              console.log('üéØ Force re-render gesture hint');
              setShowGestureHint(true);
              console.log('üéØ showGestureHint after force re-render:', true);
            }, 100);
            
            // ‚úÖ SET AUTO-HIDE TIMEOUT SAU KHI MODEL LOAD XONG
            setTimeout(() => {
              console.log(`üéØ Auto-hiding gesture hint after 5 seconds`);
              setShowGestureHint(false);
                          }, 5000);

            console.log('‚úÖ Model added to scene successfully');
            console.log('‚úÖ Scene children count:', sceneRef.current.children.length);
                                  } else {
            console.error('‚ùå Scene not available for adding model');
          }
          
        } catch (loadError) {
          console.error('‚ùå loadAsync failed:', loadError);
          throw loadError;
        }
        
        // ‚úÖ COMPLETE LOADING
        setLoadingProgress(100);
        setIsLoading(false);
        setModelInfo(`‚úÖ ${glbConfig.name} loaded successfully!`);
        
        console.log('üéâ MODEL LOADING COMPLETE!');

                                } else {
        // Kh√¥ng t√¨m th·∫•y model
        console.warn('‚ö†Ô∏è Unknown Pokemon model ID');
        setModelInfo('‚ö†Ô∏è Pokemon model kh√¥ng t·ªìn t·∫°i');

        Alert.alert(
          '‚ö†Ô∏è Model kh√¥ng t·ªìn t·∫°i',
          'QR code kh√¥ng ch·ª©a Pokemon model h·ª£p l·ªá. Vui l√≤ng th·ª≠ QR code kh√°c.',
          [{ text: 'OK' }]
        );

        setIsLoading(false);
      }
      
                    } catch (error) {
      console.error('‚ùå Error loading Pokemon model:', error);
      setModelInfo('‚ùå L·ªói t·∫£i Pokemon model');
      setIsLoading(false);
    }
  };

  const onContextCreate = async (gl: any) => {
    try {
      // Thi·∫øt l·∫≠p Scene, Camera, Renderer
      const scene = new THREE.Scene();
      const camera = new THREE.PerspectiveCamera(75, gl.drawingBufferWidth / gl.drawingBufferHeight, 0.1, 1000);
      const renderer = new Renderer({ gl });
      
      // ‚úÖ L∆ØU SCENE V√ÄO REF
      sceneRef.current = scene;
      cameraRef.current = camera;
      rendererRef.current = renderer;
      
      // ‚úÖ N·∫øu model ƒë√£ ƒë∆∞·ª£c load tr∆∞·ªõc ƒë√≥, add v√†o scene ngay
      if (modelRef.current) {
        scene.add(modelRef.current);
        console.log('üîÑ Adding existing model to new scene');
      }
      
      // ‚úÖ SETUP CAMERA - BETTER POSITION FOR FALLBACK MODELS
      camera.position.set(0, 1.0, 4.0); // ‚úÖ Closer and higher for better visibility
      camera.lookAt(0, 0, 0); // Nh√¨n th·∫≥ng v√†o center
      console.log('üéØ Camera position:', camera.position);
      renderer.setSize(gl.drawingBufferWidth, gl.drawingBufferHeight);
      renderer.setClearColor(0x000000, 0); // Trong su·ªët ƒë·ªÉ th·∫•y camera
      // @ts-ignore - alpha property for transparency
      renderer.alpha = true; // ‚úÖ ENABLE ALPHA CHANNEL
      
      // ‚úÖ ORBITCONTROLS KH√îNG T∆Ø∆†NG TH√çCH V·ªöI REACT NATIVE
      // S·ª≠ d·ª•ng touch handlers t·ª± implement thay th·∫ø
      console.log('üéÆ Using custom touch handlers for React Native compatibility');
      
      // ‚úÖ M√ÄU S·∫ÆC CHU·∫®N SRGB CHO ƒê·ªò CH√çNH X√ÅC CAO
      // @ts-ignore - t∆∞∆°ng th√≠ch nhi·ªÅu phi√™n b·∫£n three
      if ((renderer as any).outputColorSpace !== undefined) {
        // @ts-ignore
        (renderer as any).outputColorSpace = THREE.SRGBColorSpace;
                              } else {
        // @ts-ignore
        renderer.outputEncoding = THREE.sRGBEncoding;
      }
      
      // ‚úÖ PBR RENDERING CHO M√ÄU S·∫ÆC CH√çNH X√ÅC
      // @ts-ignore
      renderer.physicallyCorrectLights = true;
      // @ts-ignore
      renderer.toneMapping = THREE.ACESFilmicToneMapping;
      // @ts-ignore
      renderer.toneMappingExposure = 1.2; // TƒÉng exposure cho m√†u s·∫Øc r√µ h∆°n
      
      // ‚úÖ TEXTURE RENDERING SETTINGS
      // @ts-ignore
      renderer.antialias = true;
      // @ts-ignore
      renderer.preserveDrawingBuffer = true;
      // @ts-ignore
      renderer.powerPreference = 'high-performance';
      
      // ‚úÖ SHADOW SETTINGS CHO CHI TI·∫æT
      renderer.shadowMap.enabled = true;
      renderer.shadowMap.type = THREE.PCFSoftShadowMap;

      // ‚úÖ REFERENCES ƒê√É ƒê∆Ø·ª¢C L∆ØU ·ªû TR√äN

        // ‚úÖ √ÅNH S√ÅNG T·ªêI ∆ØU CHO M√ÄU ƒê·ªé SCIZOR
        const ambientLight = new THREE.AmbientLight(0xffffff, 1.0); // TƒÉng ambient cho m√†u ƒë·ªè
        scene.add(ambientLight);

      // ‚úÖ DIRECTIONAL LIGHT CH√çNH - CHI·∫æU S√ÅNG M·∫†NH CHO M√ÄU ƒê·ªé
      const directionalLight = new THREE.DirectionalLight(0xffffff, 2.5); // TƒÉng c∆∞·ªùng ƒë·ªô cho m√†u ƒë·ªè
      directionalLight.position.set(2, 5, 3);
      directionalLight.castShadow = true;
      directionalLight.shadow.mapSize.width = 2048;
      directionalLight.shadow.mapSize.height = 2048;
      scene.add(directionalLight);

      // ‚úÖ √ÅNH S√ÅNG B·ªî SUNG CHO M√ÄU S·∫ÆC R√ï R√ÄNG
      const leftLight = new THREE.DirectionalLight(0xffffff, 0.6);
      leftLight.position.set(-4, 3, 3);
      scene.add(leftLight);

      const rightLight = new THREE.DirectionalLight(0xffffff, 0.6);
      rightLight.position.set(4, 3, 3);
      scene.add(rightLight);
      
      // ‚úÖ POINT LIGHT CHO CHI TI·∫æT
      const pointLight = new THREE.PointLight(0xffffff, 0.8, 30);
      pointLight.position.set(0, 3, 4);
      scene.add(pointLight);
      
      // ‚úÖ RIM LIGHT CHO WINGS
      const rimLight = new THREE.DirectionalLight(0x88ccff, 0.5);
      rimLight.position.set(0, 0, -5);
      scene.add(rimLight);

      // ‚úÖ ANIMATION LOOP - T·ªêI ∆ØU HI·ªÜU SU·∫§T!
      const animate = () => {
        timeoutRef.current = setTimeout(animate, 1000 / 30); // ‚úÖ GI·∫¢M XU·ªêNG 30 FPS CHO HI·ªÜU SU·∫§T

        // ‚úÖ ORBITCONTROLS KH√îNG T∆Ø∆†NG TH√çCH V·ªöI REACT NATIVE

        // ‚úÖ UPDATE ANIMATION MIXER
        const delta = clockRef.current.getDelta();
        if (mixerRef.current) {
          mixerRef.current.update(delta);
        }

        if (modelRef.current) {
          const time = Date.now() * 0.001;

                // ‚úÖ DEBUG: Log model info occasionally (MINIMAL LOGS)
                if (Math.floor(time) % 120 === 0 && Math.floor(time * 10) % 10 === 0) {
                  // ‚úÖ LOG TEXTURE RENDERING STATUS (MINIMAL)
                  modelRef.current.traverse((child: any) => {
                              if (child.isMesh && child.material) {
                      if (!child.material.map && modelRef.current) {
                        console.log('ü¶ä No texture - force loading...');
                        forceLoadFoxTexture(modelRef.current).catch(err => {
                          console.error('Failed to load Fox texture in loop:', err);
                        });
                        
                        // ‚úÖ DEBUG: KI·ªÇM TRA ANIMATION LOOP NGAY L·∫¶N ƒê·∫¶U
                        console.log('üîç Animation Loop First Load Debug:');
                        console.log('  - No texture map found in animation loop');
                        console.log('  - Material name:', child.material.name);
                        console.log('  - Material type:', child.material.type);
                        console.log('  - Material color:', child.material.color.getHex());
                        console.log('  - Material emissive:', child.material.emissive.getHex());
                        console.log('  - Material emissiveIntensity:', child.material.emissiveIntensity);
                                  }
                                }
                              });
                }

          // Update AnimationMixer n·∫øu c√≥
          if ((modelRef.current as any).updateMixer) {
            (modelRef.current as any).updateMixer(delta);
          }
          
          // ‚úÖ BREATHING ANIMATION - T·ªêI ∆ØU!
          if ((modelRef.current as any).animate) {
            (modelRef.current as any).animate();
                            } else {
            // ‚úÖ MODEL HO√ÄN TO√ÄN Tƒ®NH - ƒê·ªÇ USER TR·∫¢I NGHI·ªÜM C·ª¨ CH·ªà T·ª∞ NHI√äN
            // Breathing effect ƒë√£ t·∫Øt ƒë·ªÉ model ƒë·ª©ng y√™n ho√†n to√†n
          }
          
          // ‚úÖ MODEL ƒê·ª®NG Y√äN BAN ƒê·∫¶U - ƒê·ªÇ USER TR·∫¢I NGHI·ªÜM C·ª¨ CH·ªà T·ª∞ NHI√äN
          // Auto-rotation ƒë√£ t·∫Øt ƒë·ªÉ user c√≥ th·ªÉ kh√°m ph√° c·ª≠ ch·ªâ m·ªôt c√°ch t·ª± nhi√™n
          
          // ‚úÖ ƒê·∫¢M B·∫¢O MODEL LU√îN TRONG T·∫¶M NH√åN
          const modelPosition = modelRef.current.position;
          const cameraPosition = camera.position;
          const distance = Math.sqrt(
            Math.pow(modelPosition.x - cameraPosition.x, 2) +
            Math.pow(modelPosition.y - cameraPosition.y, 2) +
            Math.pow(modelPosition.z - cameraPosition.z, 2)
          );
          
          // N·∫øu model qu√° xa, ƒë∆∞a v·ªÅ g·∫ßn camera
          if (distance > 5) {
            modelRef.current.position.set(0, 0, 0);
          }
        }

        renderer.render(scene, camera);
        gl.endFrameEXP();
      };

      animate();
      console.log('üé¨ 3D Scene initialized successfully!');

    } catch (error) {
      console.error('Error creating 3D context:', error);
              setIsLoading(false);
            }
  };

  if (hasPermission === null) {
    return (
      <View style={styles.container}>
        <Text style={styles.text}>ƒêang y√™u c·∫ßu quy·ªÅn truy c·∫≠p camera...</Text>
      </View>
    );
  }

  if (hasPermission === false) {
    return (
      <View style={styles.container}>
        <Text style={styles.text}>‚ùå Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p camera</Text>
        <View style={styles.button} onTouchEnd={onClose}>
          <Text style={styles.buttonText}>Quay l·∫°i</Text>
        </View>
      </View>
    );
  }

  return (
    <GestureHandlerRootView style={styles.container}>
      {/* Camera l√†m background */}
      <CameraView
        style={styles.camera}
        facing="back"
        onBarcodeScanned={scannedData ? undefined : handleBarCodeScanned}
        barcodeScannerSettings={{
          barcodeTypes: ['qr', 'pdf417'],
        }}
        pointerEvents="none"
      />

      {/* ‚úÖ SEPARATE GLVIEW AND PANRESPONDER - X·ª¨ L√ù C·ª¨ CH·ªà LI√äN T·ª§C */}
      {/* ‚úÖ GLVIEW RI√äNG BI·ªÜT - KH√îNG CH·∫∂N TOUCH EVENTS */}
        <GLView
          style={styles.glView}
          onContextCreate={onContextCreate}
        pointerEvents="none"
      />

      {/* ‚úÖ PANRESPONDER RI√äNG BI·ªÜT - X·ª¨ L√ù C·ª¨ CH·ªà LI√äN T·ª§C */}
      <View
        style={styles.touchWrapper}
        {...panResponder.panHandlers}
        onLayout={(evt) => {
          console.log('üéÆ PanResponder layout:', evt.nativeEvent.layout);
          console.log('üéÆ PanResponder zIndex: 1001, elevation: 1001');
        }}
      />

      {/* Loading Overlay */}
      {isLoading && (
        <View style={styles.loadingContainer}>
          <View style={styles.loadingCard}>
            <ActivityIndicator size="large" color="#FFD700" />
            <Text style={styles.loadingText}>{modelInfo}</Text>

            <View style={styles.progressBarContainer}>
              <View style={[styles.progressBar, { width: `${loadingProgress}%` }]} />
            </View>
            <Text style={styles.progressText}>{loadingProgress}%</Text>

            <Text style={styles.systemInfo}>üéÆ Pokemon AR System</Text>
          </View>
        </View>
      )}

      {/* UI Controls */}
      <View style={styles.overlay}>
        {/* ‚úÖ FIX: UI NH·∫§T QU√ÅN - THAY ƒê·ªîI THEO TR·∫†NG TH√ÅI */}
        {!scannedData ? (
          <Text style={styles.instruction}>
            üì± Qu√©t QR code ƒë·ªÉ hi·ªÉn th·ªã Pokemon 3D
          </Text>
        ) : (
          <View>
            <Text style={styles.instruction}>
              ü¶Ç {modelInfo || 'Pokemon ƒë√£ s·∫µn s√†ng!'}
            </Text>
            {/* ‚úÖ TC6.1: ANIMATION FEEDBACK UI */}
            {animationFeedback && (
              <Text style={styles.animationFeedback}>
                {animationFeedback}
              </Text>
            )}
          </View>
        )}

        {/* ‚úÖ REMOVED INSTRUCTION TEXT AS REQUESTED */}

        {/* ‚úÖ CH·ªà HI·ªÜN KHI ƒêANG LOADING ƒê·ªÇ TR√ÅNH R·ªêI UI */}
        {scannedData && isLoading && (
          <Text style={styles.scannedData}>
            üîç ƒê√£ qu√©t: {scannedData}
          </Text>
        )}

        {/* ‚úÖ GESTURE HINT - H∆Ø·ªöNG D·∫™N T∆Ø∆†NG T√ÅC */}
        {scannedData && !isLoading && showGestureHint && (
          <View style={styles.gestureHint}>
            <Text style={styles.gestureHintText}>
              üëÜ Vu·ªët ƒë·ªÉ xoay ‚Ä¢ ü§è Ch·ª•m ƒë·ªÉ zoom
            </Text>
          </View>
        )}



        <View
          style={styles.closeButton}
          onTouchEnd={onClose}
        >
          <Text style={styles.closeText}>‚ùå ƒê√≥ng</Text>
        </View>
      </View>
    </GestureHandlerRootView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#000',
  },
  camera: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
  },
  glContainer: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    width: '100%',
    height: '100%',
    justifyContent: 'center',
    alignItems: 'center',
    pointerEvents: 'box-none',
  },
  touchWrapper: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    zIndex: 1001, // ‚úÖ CAO H∆†N GESTURE HINT V√Ä DEBUG INFO
    backgroundColor: 'transparent',
    elevation: 1001, // Android elevation
  },
  glView: {
    flex: 1,
    backgroundColor: 'transparent',
  },
  overlay: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    justifyContent: 'space-between',
    zIndex: 1000, // ‚úÖ UI ELEMENTS LU√îN ·ªû TR√äN 3D MODEL
    alignItems: 'center',
    // ‚úÖ TC6.2: ADAPTIVE PADDING FOR DIFFERENT DEVICES
    paddingTop: Platform.OS === 'ios' ? (Dimensions.get('window').height > 800 ? 60 : 40) : 30,
    paddingBottom: Platform.OS === 'ios' ? 40 : 30,
    paddingHorizontal: 20,
  },
  instruction: {
    color: '#fff',
    // ‚úÖ TC6.2: RESPONSIVE FONT SIZE
    fontSize: Dimensions.get('window').width < 375 ? 16 : 18,
    fontWeight: 'bold',
    textAlign: 'center',
    backgroundColor: 'rgba(0,0,0,0.8)', // ‚úÖ TƒÇNG OPACITY CHO R√ï R√ÄNG
    paddingHorizontal: 20,
    paddingVertical: 10,
    borderRadius: 10,
    marginTop: 20,
    borderWidth: 1,
    borderColor: 'rgba(255, 255, 255, 0.2)', // ‚úÖ VI·ªÄN TR·∫ÆNG NH·∫∏
    // ‚úÖ TC6.2: ENSURE VISIBILITY ON ALL DEVICES
    maxWidth: Dimensions.get('window').width - 40,
  },
  subInstruction: {
    color: '#fff',
    fontSize: 14,
    textAlign: 'center',
    backgroundColor: 'rgba(0,0,0,0.6)',
    paddingHorizontal: 20,
    paddingVertical: 8,
    borderRadius: 10,
    marginTop: 10,
  },
  scannedData: {
    color: '#FFD700',
    fontSize: 12,
    textAlign: 'center',
    backgroundColor: 'rgba(0,0,0,0.8)',
    paddingHorizontal: 15,
    paddingVertical: 5,
    borderRadius: 15,
    marginTop: 5,
  },
  closeButton: {
    backgroundColor: 'rgba(255,0,0,0.7)',
    paddingHorizontal: 30,
    paddingVertical: 15,
    borderRadius: 25,
    marginBottom: 20,
  },
  closeText: {
    color: '#fff',
    fontSize: 16,
    fontWeight: 'bold',
  },
  // ‚úÖ TC6.1: ANIMATION FEEDBACK STYLES
  animationFeedback: {
    color: '#FFD700',
    fontSize: 24,
    fontWeight: 'bold',
    textAlign: 'center',
    backgroundColor: 'rgba(0,0,0,0.8)',
    paddingHorizontal: 20,
    paddingVertical: 8,
    borderRadius: 20,
    marginTop: 10,
    borderWidth: 2,
    borderColor: '#FFD700',
    shadowColor: '#FFD700',
    shadowOffset: { width: 0, height: 0 },
    shadowOpacity: 0.8,
    shadowRadius: 10,
  },
  loadingContainer: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    backgroundColor: 'rgba(0, 0, 0, 0.8)',
    justifyContent: 'center',
    alignItems: 'center',
    zIndex: 1000,
  },
  loadingCard: {
    backgroundColor: 'rgba(255, 255, 255, 0.95)',
    padding: 30,
    borderRadius: 20,
    alignItems: 'center',
    minWidth: 280,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 8,
    elevation: 10,
  },
  loadingText: {
    color: '#333',
    fontSize: 16,
    fontWeight: '600',
    marginTop: 15,
    marginBottom: 20,
    textAlign: 'center',
  },
  progressBarContainer: {
    width: 200,
    height: 6,
    backgroundColor: '#E0E0E0',
    borderRadius: 3,
    overflow: 'hidden',
    marginBottom: 10,
  },
  progressBar: {
    height: '100%',
    backgroundColor: '#FFD700',
    borderRadius: 3,
  },
  progressText: {
    color: '#666',
    fontSize: 14,
    fontWeight: '500',
    marginBottom: 10,
  },
  systemInfo: {
    color: '#4CAF50',
    fontSize: 12,
    fontWeight: '500',
    textAlign: 'center',
  },
  button: {
    backgroundColor: '#007AFF',
    paddingHorizontal: 30,
    paddingVertical: 15,
    borderRadius: 25,
    marginTop: 20,
  },
  buttonText: {
    color: '#fff',
    fontSize: 16,
    fontWeight: 'bold',
  },
  text: {
    color: '#fff',
    fontSize: 16,
    textAlign: 'center',
  },
  // ‚úÖ GESTURE HINT STYLES
  gestureHint: {
    backgroundColor: 'rgba(0,0,0,0.8)',
    paddingHorizontal: 20,
    paddingVertical: 12,
    borderRadius: 25,
    marginTop: 20,
    borderWidth: 1,
    borderColor: 'rgba(255,255,255,0.3)',
    zIndex: 1000,
    pointerEvents: 'none',
  },
  gestureHintText: {
    color: '#FFD700',
    fontSize: 14,
    fontWeight: '600',
    textAlign: 'center',
  },
  // ‚úÖ DEBUG STYLES
  debugInfo: {
    backgroundColor: 'rgba(255,0,0,0.8)',
    paddingHorizontal: 15,
    paddingVertical: 8,
    borderRadius: 15,
    marginTop: 10,
    zIndex: 1000,
    pointerEvents: 'none',
  },
  debugText: {
    color: '#fff',
    fontSize: 12,
    fontWeight: 'bold',
    textAlign: 'center',
  },
});

export default PokemonARViewer;
